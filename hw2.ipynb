{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/isa-pinheiro/Learning-From-Data/blob/main/hw2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-lONzo8kJ4H"
      },
      "source": [
        "\n",
        "# Hoeffding Inequality\n",
        "Run a computer simulation for flipping 1,000 virtual fair coins. Flip each coin independently 10 times. Focus on 3 coins as follows: c1 is the first coin flipped, crand is a coin chosen randomly from the 1,000, and cmin is the coin which had the minimum frequency of heads (pick the earlier one in case of a tie). Let ν1, νrand, and νmin be the fraction of heads obtained for the 3 respective coins out of the 10 tosses.\n",
        "\n",
        "Run the experiment 100,000 times in order to get a full distribution of ν1, vrand, and νmin (note that crand and cmin will change from run to run)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nkats5oXjpY2"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dq7CPaPrksnv"
      },
      "outputs": [],
      "source": [
        "# 1 represents heads and 0 represents tails\n",
        "# função de criar as moedas\n",
        "# retornar a frequencia\n",
        "\n",
        "def flip_coin(n):\n",
        "    state = np.empty((0,n))\n",
        "\n",
        "    for _ in range(10):\n",
        "        state = np.append(state, random.randint(0,1))\n",
        "\n",
        "    v = (state.sum())/n\n",
        "\n",
        "    return v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wchQuXR4ky18"
      },
      "outputs": [],
      "source": [
        "# cria as 1000 moedas\n",
        "\n",
        "def create_n_coins(n_flips, n_coins):\n",
        "    v = np.empty((0, n_coins))\n",
        "\n",
        "    for _ in range(n_coins):\n",
        "        v = np.append(v, flip_coin(n_flips))\n",
        "\n",
        "    v1 = v[0]\n",
        "    vrand = v[random.randint(0,n_coins-1)]\n",
        "    vmin = v.min()\n",
        "    # print(v)\n",
        "    # print(v1, vrand, vmin)\n",
        "    return v1, vrand, vmin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QKDsHBYisKcR",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "total_v1, total_vrand, total_vmin = [], [], []\n",
        "\n",
        "for i in range(100000):\n",
        "    # print(i)\n",
        "    v1, vrand, vmin = create_n_coins(10, 1000)\n",
        "    total_v1.append(v1)\n",
        "    total_vrand.append(vrand)\n",
        "    total_vmin.append(vmin)\n",
        "\n",
        "    if i == 0:\n",
        "        actual_v1 = v1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hKd9N4I5toj6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eaeb30c2-62b0-40f0-c803-c7a9ded2fca7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "média v1 0.4945\n",
            "média vrand 0.49639999999999995\n",
            "média vmin 0.039599999999999996\n"
          ]
        }
      ],
      "source": [
        "print('média v1', np.mean(total_v1))\n",
        "print('média vrand', np.mean(total_vrand))\n",
        "print('média vmin', np.mean(total_vmin))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear Regression\n",
        "In these problems, we will explore how Linear Regression for classification works. As\n",
        "with the Perceptron Learning Algorithm in Homework # 1, you will create your own\n",
        "target function f and data set D. Take d = 2 so you can visualize the problem, and\n",
        "assume X = [−1, 1] × [−1, 1] with uniform probability of picking each x ∈ X . In\n",
        "each run, choose a random line in the plane as your target function f (do this by\n",
        "taking two random, uniformly distributed points in [−1, 1] × [−1, 1] and taking the\n",
        "line passing through them), where one side of the line maps to +1 and the other maps\n",
        "to −1. Choose the inputs xn of the data set as random points (uniformly in X ), and\n",
        "evaluate the target function on each xn to get the corresponding output yn."
      ],
      "metadata": {
        "id": "tOCRTYKNwBxW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_data(N_train, N_test):\n",
        "    # y = ax +b\n",
        "    # p = (x, y)\n",
        "\n",
        "    p1 = np.random.uniform(-1, 1, 2)\n",
        "    p2 = np.random.uniform(-1, 1, 2)\n",
        "\n",
        "    a = (p1[1] - p2[1]) / (p1[0] - p2[0])\n",
        "    b = p1[1] - a * p1[0]\n",
        "\n",
        "    X_train = np.random.uniform(-1, 1, (N_train, 2))\n",
        "    y_train = np.sign((a * X_train[:, 0] + b) - X_train[:, 1])\n",
        "\n",
        "    X_test = np.random.uniform(-1, 1, (N_test, 2))\n",
        "    y_test = np.sign((a * X_test[:, 0] + b) - X_test[:, 1])\n",
        "\n",
        "    X_train = np.concatenate((np.ones((X_train.shape[0], 1)), X_train), axis=1)\n",
        "    X_test = np.concatenate((np.ones((X_test.shape[0], 1)), X_test), axis=1)\n",
        "    return X_train, y_train, X_test, y_test, a, b\n",
        "\n"
      ],
      "metadata": {
        "id": "ifSbtigrwQmT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def missed_index(y_true, y_pred):\n",
        "    mis_i = []\n",
        "    for i in range(y_true.shape[0]):\n",
        "        if y_true[i] != y_pred[i]:\n",
        "            mis_i.append(i)\n",
        "    return mis_i"
      ],
      "metadata": {
        "id": "hhWHj4j-yD5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def perceptron(X_train, X_test, y_train, y_test, w = np.zeros(3)):\n",
        "    total_iter = []\n",
        "    total_error = []\n",
        "    for _ in range(1000):\n",
        "        iter = 0\n",
        "\n",
        "        while True:\n",
        "            iter += 1\n",
        "\n",
        "            y_pred_train = np.sign(np.dot(X_train, w.T))\n",
        "\n",
        "            mis_i_train = missed_index(y_train, y_pred_train)\n",
        "\n",
        "            if len(mis_i_train) == 0:\n",
        "                break\n",
        "\n",
        "            rand_i = mis_i_train[random.randint(0, len(mis_i_train) - 1)]\n",
        "\n",
        "            w = w + y_train[rand_i] * X_train[rand_i]\n",
        "\n",
        "        total_iter.append(iter)\n",
        "\n",
        "        # calculo do erro\n",
        "        y_pred_test = np.sign(np.dot(X_test, w.T))\n",
        "\n",
        "        mis_i_test = missed_index(y_test, y_pred_test)\n",
        "\n",
        "        error = len(mis_i_test)/1000\n",
        "\n",
        "        total_error.append(error)\n",
        "    return np.mean(total_iter), np.mean(total_error)"
      ],
      "metadata": {
        "id": "wE34EO8KEf76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def linear_regression(N_train, N_test):\n",
        "    total_error_train = []\n",
        "    total_error_test = []\n",
        "\n",
        "    for _ in range(1000):\n",
        "        X_train, y_train, X_test, y_test, a, b = create_data(N_train, N_test)\n",
        "\n",
        "        X_train_pinv = np.linalg.pinv(X_train)\n",
        "        w = np.dot(X_train_pinv, y_train)\n",
        "\n",
        "        y_pred_train = np.sign(np.dot(X_train, w.T))\n",
        "\n",
        "        mis_i_train = missed_index(y_train, y_pred_train)\n",
        "\n",
        "        error_train = len(mis_i_train)/N_train\n",
        "\n",
        "        total_error_train.append(error_train)\n",
        "\n",
        "        # calculo do erro\n",
        "        y_pred_test = np.sign(np.dot(X_test, w.T))\n",
        "\n",
        "        mis_i_test = missed_index(y_test, y_pred_test)\n",
        "\n",
        "        error_test = len(mis_i_test)/N_test\n",
        "\n",
        "        total_error_test.append(error_test)\n",
        "\n",
        "    return np.mean(total_error_train), np.mean(total_error_test)"
      ],
      "metadata": {
        "id": "uZ4opBbVi4rn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def linear_regressionwpla(N_train, N_test):\n",
        "    total_error_train = []\n",
        "    total_error_test = []\n",
        "\n",
        "    for _ in range(1000):\n",
        "        X_train, y_train, X_test, y_test, a, b = create_data(N_train, N_test)\n",
        "\n",
        "        X_train_pinv = np.linalg.pinv(X_train)\n",
        "        w = np.dot(X_train_pinv, y_train)\n",
        "\n",
        "        y_pred_train = np.sign(np.dot(X_train, w.T))\n",
        "\n",
        "        mis_i_train = missed_index(y_train, y_pred_train)\n",
        "\n",
        "        error_train = len(mis_i_train)/N_train\n",
        "\n",
        "        total_error_train.append(error_train)\n",
        "\n",
        "        # calculo do erro\n",
        "        y_pred_test = np.sign(np.dot(X_test, w.T))\n",
        "\n",
        "        mis_i_test = missed_index(y_test, y_pred_test)\n",
        "\n",
        "        error_test = len(mis_i_test)/N_test\n",
        "\n",
        "        total_error_test.append(error_test)\n",
        "\n",
        "        iter_pla, error_pla = perceptron(X_train, X_test, y_train, y_test, w)\n",
        "    return np.mean(total_error_train), np.mean(total_error_test), iter_pla, error_pla"
      ],
      "metadata": {
        "id": "Ps8sj6_vyG9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Questões 5 e 6\n",
        "total_error_train, total_error_test = linear_regression(N_train = 100, N_test = 1000)\n",
        "print('media de erro no treino', total_error_train)\n",
        "print('media de erro no teste', total_error_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WN_XnKLeEoZl",
        "outputId": "f556ac12-a3ea-43e1-820f-b699bfd8dea0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "media de erro no treino 0.038680000000000006\n",
            "media de erro no teste 0.048196\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_, _, iter_pla, error_pla = linear_regressionwpla(N_train = 10, N_test = 1000)\n",
        "print('media de iterações', iter_pla)\n",
        "print('media de erro', error_pla)"
      ],
      "metadata": {
        "id": "MQuXCuosKKnA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6873776c-457e-4f8e-ff88-2a21cb246e62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "media de iterações 1.0\n",
            "media de erro 0.08899999999999998\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nonlinear Transformation\n",
        "In these problems, we again apply Linear Regression for classification. Consider the\n",
        "target function: \\\\\n",
        " \\\\\n",
        "f(x1, x2) = sign(x1^2 + x2^2 − 0.6) \\\\\n",
        " \\\\\n",
        "Generate a training set of N = 1000 points on X = [−1, 1] × [−1, 1] with a uniform\n",
        "probability of picking each x ∈ X . Generate simulated noise by flipping the sign of\n",
        "the output in a randomly selected 10% subset of the generated training set."
      ],
      "metadata": {
        "id": "d-vg14inbbHu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_noisy_data(N_train, N_test):\n",
        "    # y = ax +b\n",
        "    # p = (x, y)\n",
        "    X_train = np.random.uniform(-1, 1, (N_train, 2))\n",
        "    y_train = np.sign(np.square(X_train[:, 0]) + np.square(X_train[:, 1]) - 0.6)\n",
        "\n",
        "    X_test = np.random.uniform(-1, 1, (N_test, 2))\n",
        "    y_test = np.sign(np.square(X_test[:, 0]) + np.square(X_test[:, 1]) - 0.6)\n",
        "\n",
        "    rand_i_train = np.random.choice(y_train.size, size=(int(len(y_train) * 0.1)), replace=False)\n",
        "    y_train[rand_i_train] = -y_train[rand_i_train]\n",
        "\n",
        "    rand_i_test = np.random.choice(y_test.size, size=(int(len(y_test) * 0.1)), replace=False)\n",
        "    y_test[rand_i_test] = -y_test[rand_i_test]\n",
        "\n",
        "    X_train = np.concatenate((np.ones((X_train.shape[0], 1)), X_train), axis=1)\n",
        "    X_test = np.concatenate((np.ones((X_test.shape[0], 1)), X_test), axis=1)\n",
        "\n",
        "    return X_train, y_train, X_test, y_test\n"
      ],
      "metadata": {
        "id": "eGaGTOoQeqJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (1, x1, x2, x1x2, x1^2, x2^2)\n",
        "\n",
        "def transform(X):\n",
        "    Z = np.zeros((X.shape[0], 6))\n",
        "    Z[:, 0] = 1\n",
        "    Z[:, 1] = X[:, 1]\n",
        "    Z[:, 2] = X[:, 2]\n",
        "    Z[:, 3] = X[:, 1] * X[:, 2]\n",
        "    Z[:, 4] = np.square(X[:, 1])\n",
        "    Z[:, 5] = np.square(X[:, 2])\n",
        "    return Z\n"
      ],
      "metadata": {
        "id": "Q0PFpbZvBAt_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def linear_regression_noisy(N_train, N_test, will_transform = False):\n",
        "    total_error_train = []\n",
        "    total_error_test = []\n",
        "    all_w = []\n",
        "    for _ in range(1000):\n",
        "        X_train, y_train, X_test, y_test = create_noisy_data(N_train, N_test)\n",
        "        if transform:\n",
        "            X_train = transform(X_train)\n",
        "            X_test = transform(X_test)\n",
        "\n",
        "        X_train_pinv = np.linalg.pinv(X_train)\n",
        "        w = np.dot(X_train_pinv, y_train)\n",
        "\n",
        "        all_w.append(w)\n",
        "        y_pred_train = np.sign(np.dot(X_train, w.T))\n",
        "\n",
        "        mis_i_train = missed_index(y_train, y_pred_train)\n",
        "\n",
        "        error_train = len(mis_i_train)/N_train\n",
        "\n",
        "        total_error_train.append(error_train)\n",
        "\n",
        "        # calculo do erro\n",
        "        y_pred_test = np.sign(np.dot(X_test, w.T))\n",
        "\n",
        "        mis_i_test = missed_index(y_test, y_pred_test)\n",
        "\n",
        "        error_test = len(mis_i_test)/N_test\n",
        "\n",
        "        total_error_test.append(error_test)\n",
        "\n",
        "    return np.mean(total_error_train), np.mean(total_error_test), all_w"
      ],
      "metadata": {
        "id": "NjqkwUE4jZKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N_train = 1000\n",
        "N_test = 1000"
      ],
      "metadata": {
        "id": "iqbICNP3oZ47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Questão 08\n",
        "error_mean_train, error_mean_test, _ = linear_regression_noisy(N_train, N_test)\n",
        "error_mean_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkfZT0F_gdVI",
        "outputId": "0c10b846-5ba5-4f00-8d14-bb39c775c621"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.12399700000000001"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transf_error_mean_train, transf_error_mean_test, w_mean = linear_regression_noisy(N_train, N_test, True)"
      ],
      "metadata": {
        "id": "r0XCpbXy88L-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transf_error_mean_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFwUE2QL-IY4",
        "outputId": "99c02169-2394-404f-ab92-fd61df68651f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.12372"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w_mean = np.mean(w_mean, axis=0)\n",
        "[f\"{w:.6f}\" for w in w_mean]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUHl-jIP-vDs",
        "outputId": "547bf336-96b2-48da-feba-5bc0d46a61c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['-0.992470', '0.002163', '-0.000701', '0.001885', '1.559744', '1.558534']"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPUE7pq0TH+pe4RUZPKvp90",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}